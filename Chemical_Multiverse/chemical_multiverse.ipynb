{"cells":[{"cell_type":"markdown","metadata":{"id":"M2xGGIy-Z0aC"},"source":["# Packeges"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":48974,"status":"ok","timestamp":1746473225415,"user":{"displayName":"Israel Castañeda","userId":"17651928571784521078"},"user_tz":360},"id":"GCedfQZlZjJt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f20906c-3002-4ee8-852b-53582f1dc5a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.0/357.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for molplotly (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for molvs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip -q install rdkit==2024.3.4\n","!pip -q install scikit-fingerprints\n","!pip -q install kora py3Dmol\n","!pip -q install kaleido\n","!pip -q install jupyter-dash\n","!pip -q install molplotly --no-deps\n","!pip -q install molvs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BqqrJfR3Q76a"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import kaleido\n","import molplotly\n","from rdkit import Chem, RDConfig\n","from rdkit.Chem.SaltRemover import SaltRemover\n","from rdkit import DataStructs\n","from rdkit.Chem import AllChem\n","from rdkit.Chem import Draw\n","from rdkit.Chem import PandasTools, Scaffolds\n","from rdkit.Chem import Descriptors, Descriptors3D\n","from rdkit.DataStructs.cDataStructs import ExplicitBitVect\n","import kora.install.rdkit\n","from skfp.fingerprints import MAPFingerprint\n","import plotly.express as px\n","import matplotlib.pyplot as plt\n","from rdkit.Chem import rdMolDescriptors\n","from molvs.standardize import Standardizer\n","from molvs.charge import Uncharger, Reionizer\n","from molvs.fragment import LargestFragmentChooser\n","from molvs.tautomer import TautomerCanonicalizer\n","from rdkit.Chem.rdmolops import GetFormalCharge, RemoveStereochemistry\n","from sklearn.preprocessing import StandardScaler\n","from rdkit.Chem import MACCSkeys, RDKFingerprint, Pharm2D\n","from rdkit.Chem.Pharm2D import Gobbi_Pharm2D, Generate\n","import sklearn\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","import math\n","from math import pi\n","from IPython.display import display, SVG, HTML\n","import json\n","from scipy.spatial import distance\n","from jupyter_dash import JupyterDash\n","from itertools import combinations\n","from joblib import Parallel, delayed\n","from sklearn.manifold import trustworthiness\n","from scipy.stats import pearsonr\n","from sklearn.metrics.pairwise import pairwise_distances\n","from google.colab.output import serve_kernel_port_as_iframe\n","import plotly.io as pio"]},{"cell_type":"markdown","metadata":{"id":"VoYrmWDPXH3d"},"source":["# Funtion\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8m_mQipUy1S"},"outputs":[],"source":["                        #Dataset settings\n","def chemical_multiverse(dataset=None, ID=None, smiles_column_name=None, target_activities=[None],\n","\n","                        #Calculation settings\n","                        vPCA=True, t_SNE=True, MACCS=True, ECFP=True, radius=3, druglikeness_descriptors=True, MAP4=True, signaturizer_code=['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5'],\n","\n","                        #Visualization settings\n","                        palette='hsv_r', size_point=12.0, size_point_representation='normal_desviation',   point_shape='circle',\n","\n","                        #Color scale configuration\n","                        evaluation_metric='mpIC50_value', metric_name='mpIC50',\n","\n","                        #t_SNE configuration\n","                        perplexity=33, n_iterations=1000,\n","\n","                        #Parallelization\n","                        n_jobs=-1):\n","\n","   \"\"\"\n","   Function designed to visualize a chemical multiverse with multiple activities or properties in an interactive scatter plot for a compound set.\n","\n","   Args:\n","      dataset (CSV, XLSX, TSV, JSON, XML): DataFrame of compounds provided by the user.\n","\n","      ID (str): Column name containing the ID of each compound.\n","\n","      smiles_column_name (str): Column name containing SMILES notation.\n","\n","      target_activities (list): List with the names of columns containing target activity values.\n","\n","      vPCA (bool): User-defined variable for applying PCA.\n","\n","      t_SNE (bool): User-defined variable for applying t-SNE.\n","\n","      MACCS (bool): User-defined variable for applying MACCS keys.\n","\n","      ECFP (bool): User-defined variable for applying ECFP.\n","\n","      radius (int): User-defined variable for ECFP radius 2 or 3.\n","\n","      druglikeness_descriptors (bool): User-defined variable for applying the 6 drug-likeness descriptors.\n","\n","      signaturizer_code (list): User-defined variable for applying signaturizer with 6 different codes.\n","\n","      palette (str): User-defined variable for defining a continuous color palette.\n","\n","      perplexity (int): User-defined variable for adjusting the proximity of points in t-SNE, depending on dataset size.\n","\n","      size_point (float): User-defined variable for adjusting point size in the plot.\n","\n","      size_point_representation (str): User-defined variable for adjusting point size in the plot.\n","\n","      point_shape (str): User-defined variable for adjusting point shape in the plot.\n","\n","      evaluation_metric (str): User-defined variable for adjusting point shape in the plot.\n","\n","      metric_name (str): User-defined variable for adjusting point shape in the plot.\n","\n","      n_iterations (int): Number of iterations for t-SNE.\n","\n","      n_jobs(int): Number of cores to parallelize the process\n","\n","\n","   Returns:\n","    Up to 50 interactive plots.\n","    DataFrame with all calculations performed.\n","   \"\"\"\n","\n","\n","\n","   def pretreatment(smi:str)->str:\n","\n","        \"\"\"\n","        SMILES Preprocessing: from the SMILES column, filters by allowed atoms and applies the STD, LFC, UC, RI and TC functions.\n","\n","        Args:\n","            smi (str): SMILES to preprocess; name of the column containing the SMILES.\n","\n","        Returns:\n","            str: Preprocessed SMILES or the corresponding error message.\n","        \"\"\"\n","        try:\n","            mol = Chem.MolFromSmiles(smi)\n","            if mol is None:\n","                return \"Invalid SMILES\"\n","            mol = STD(mol)\n","            mol = LFC(mol)\n","            allowed_elements = {\"H\",\"B\",\"C\",\"N\",\"O\",\"F\",\"Si\",\"P\",\"S\",\"Cl\",\"Se\",\"Br\",\"I\"}\n","            actual_elements = set([atom.GetSymbol() for atom in mol.GetAtoms()])\n","            if len(actual_elements-allowed_elements) == 0:\n","                mol = UC(mol)\n","                mol = RI(mol)\n","                mol = TC(mol)\n","                return Chem.MolToSmiles(mol)\n","            else:\n","                return \"Disallowed elements in SMILES\"\n","        except Exception as e:\n","            return f'Error: {str(e)}'\n","\n","   def parallel_pretreatment(data_frame:pd.DataFrame, smiles_column_name, n_jobs=n_jobs)->pd.DataFrame:\n","       '''\n","       Parallelize the pretreatment of Smiles\n","\n","       Arg:\n","          data_frame(pd.DataFrame): DataFrame containing SMILES\n","          smiles_column_name(str): Name of the column containing SMILES\n","          n_jobs(int): Number of cores to parallelize the process\n","\n","       Returns:\n","          data_frame(pd.DataFrame): DataFrame with the new column\n","       '''\n","\n","       if n_jobs == -1:\n","          import multiprocessing\n","          n_jobs = multiprocessing.cpu_count()\n","\n","       with Parallel(n_jobs=n_jobs) as parallel:\n","            canonical_smiles = parallel(delayed(pretreatment)(smiles) for smiles in data_frame[smiles_column_name])\n","\n","       data_frame['Canonical_Smiles'] = canonical_smiles\n","       data_frame = data_frame[~data_frame[\"Canonical_Smiles\"].isin([\"Invalid SMILES\", \"Disallowed elements in SMILES\", \"Error general\"])].reset_index(drop=True)\n","       return data_frame\n","\n","\n","   def similarity_calc(smi1:str, smi2:str, method:str='tanimoto', fp_type:str='MACCS')->list:\n","\n","        \"\"\"\n","        Similarity calculation between two compounds based on their processed SMILES.\n","\n","        Args:\n","            smi1 (str): SMILES of the first compound to compare.\n","            smi2 (str): SMILES of the second compound to compare.\n","            method (str): Comparison method to use. Can be 'tanimoto'\n","            fp_type (str): Type of fingerprint to use. Can be 'MACCS' or 'ECFP' with radius 2 or 3.\n","\n","        Returns:\n","            similarity (float): Similarity coefficient between the compounds.\n","        \"\"\"\n","\n","        mol1 = Chem.MolFromSmiles(smi1)\n","        mol2 = Chem.MolFromSmiles(smi2)\n","\n","        if fp_type == 'MACCS':\n","            fp1 = MACCSkeys.GenMACCSKeys(mol1)\n","            fp2 = MACCSkeys.GenMACCSKeys(mol2)\n","        elif fp_type == 'ECFP':\n","            fp1 = AllChem.GetMorganFingerprintAsBitVect(mol1, radius, nBits=2048)\n","            fp2 = AllChem.GetMorganFingerprintAsBitVect(mol2, radius, nBits=2048)\n","\n","        if method == 'tanimoto':\n","            similarity = round(DataStructs.TanimotoSimilarity(fp1, fp2), 3)\n","        return similarity\n","\n","\n","   def numpy_to_bitvect(array)->ExplicitBitVect:\n","\n","       bitvect = ExplicitBitVect(len(array))\n","       for i, value in enumerate(array):\n","           if value:\n","               bitvect.SetBit(i)\n","       return bitvect\n","\n","\n","   def map4_tanimoto_calculation(fps_bitvect):\n","\n","       n = len(fps_bitvect)\n","       sim_matrix = np.zeros((n, n))\n","       for i in range(n):\n","           for j in range(i+1, n):\n","               sim_matrix[i, j] = DataStructs.TanimotoSimilarity(fps_bitvect[i], fps_bitvect[j])\n","               sim_matrix[j, i] = sim_matrix[i, j]\n","       return sim_matrix\n","\n","\n","   def calculate_all_similarities_blocks(fp_type:str='MACCS', method:str='tanimoto')->pd.DataFrame:\n","        '''\n","        Similarity calculations between all pair of compounds using block processing.\n","\n","        Args:\n","            fp_type (str): Type of fingerprint to use. Can be 'MACCS', 'ECFP' and MAP4 with radius 2 or 3.\n","            method (str): Comparison method to use. Can be 'tanimoto'\n","            block_size (int): Number of compounds to process in each block.\n","\n","        Returns:\n","            similarity_df (pd.DataFrame): DataFrame with the similarity between all pairs of compounds.\n","        '''\n","        smiles = input_df[\"Canonical_Smiles\"].to_list()\n","        compounds_ids = input_df[ID].to_list()\n","        num_smiles = len(smiles)\n","\n","        if num_smiles <= 1000:\n","          block_size = 500\n","        elif num_smiles <=10000:\n","          block_size = 500\n","        else:\n","          block_size = 1000\n","\n","        matrix = np.zeros((num_smiles, num_smiles))\n","\n","        for i_start in range(0, num_smiles, block_size):\n","            i_end = min(i_start + block_size, num_smiles)\n","            for j_start in range(0, num_smiles, block_size):\n","                j_end = min(j_start + block_size, num_smiles)\n","                block_pairs = [(i,j) for i in range(i_start, i_end) for j in range(j_start, j_end) if i < j]\n","                with Parallel(n_jobs=n_jobs) as parallel:\n","                    block_similarities = parallel(delayed(similarity_calc)(smiles[i], smiles[j], method=method, fp_type=fp_type) for i, j in block_pairs)\n","\n","                #Map the similarities back to the matrix\n","                k=0\n","                for i,j in block_pairs:\n","                    matrix[i,j] = block_similarities[k]\n","                    matrix[j,i] = block_similarities[k]\n","                    k+=1\n","\n","        np.fill_diagonal(matrix, 1.0)\n","\n","        similarity_df = pd.DataFrame(matrix, index=compounds_ids, columns=compounds_ids)\n","\n","\n","        return similarity_df\n","\n","\n","   def evaluate_metric(data_frame:pd.DataFrame, evaluation_metric:str='norma_desviation', metric_name:str='mpIC50')->float:\n","        \"\"\"\n","        Generate a custom metric based on columns from a DataFrame and stores the result in a new column\n","\n","        Arg:\n","           data_frame (str): pd.DataFrame, name of the dataframe containing the columns requerid for the evaluation\n","           evaluation_metric (str): Mathematical spression defining how to combine the columns. Example: '(-log(Activity1) + Activity2 - 0.5 * Activity3)'\n","           metric_name (str): Name of the new column where the results will be stored and the names showed in th graphics\n","\n","        Returns:\n","           data_frame (pd.DataFrame): DataFrame with the new column\n","        \"\"\"\n","\n","        columns_in_expression = re.findall(r'[A-Za-z_][A-Za-z_0-9]*',evaluation_metric)\n","\n","        missing_columns = [col for col in columns_in_expression if col not in data_frame.columns and not col.isnumeric()]\n","        if missing_columns:\n","          raise ValueError(f\"Error: The following columns are missing in the provided dataset: {', '.join(missing_columns)}\")\n","\n","\n","        expression_to_evaluate = evaluation_metric\n","        for col in columns_in_expression:\n","           if col in data_frame.columns:\n","             expression_to_evaluate = expression_to_evaluate.replace(col, f'data_frame[\"{col}\"]')\n","\n","        try:\n","          data_frame[metric_name] = eval(expression_to_evaluate)\n","        except Exception as e:\n","          raise ValueError(f\"Error: {e}\")\n","\n","        return data_frame\n","\n","   def applying_pca(data, n_components=2):\n","\n","     '''\n","     Apply PCA to the data and return the transformated data.\n","\n","     '''\n","     pca = PCA(n_components=n_components)\n","     pca_results = pca.fit_transform(data)\n","     explained_variance = pca.explained_variance_ratio_\n","     return pca_results, explained_variance\n","\n","\n","   def applying_tsne(data, perplexity: int, n_iterations: int):\n","\n","     tsne = TSNE(n_components=2, verbose=0, perplexity=perplexity)\n","     tsne_results = tsne.fit_transform(data)\n","     return tsne_results\n","\n","\n","   def configure_plot_layout(fig:plt, data_frame:pd.DataFrame, size_point_representation)->plt:\n","\n","      \"\"\"\n","      Plot layout configuration.\n","\n","      Args:\n","          fig: plot to configure.\n","          data_frame: DataFrame containing the plot data.\n","\n","      Returns:\n","          fig: Plot with configured layout.\n","      \"\"\"\n","\n","      fig.update_layout(\n","          title_font=dict(size=25),\n","          plot_bgcolor='white',\n","          paper_bgcolor='white',\n","          xaxis=dict(mirror=True, showgrid=False, showline=True, zeroline=False, linecolor='black', title_font=dict(size=30),tickfont=dict(size=25)),\n","          yaxis=dict(mirror=True, showgrid=False, showline=True, zeroline=False, linecolor='black', title_font=dict(size=30), tickfont=dict(size=25)),\n","          coloraxis_colorbar=dict(title=metric_name, title_side= 'bottom', orientation=\"h\", xanchor='center', yanchor='bottom', thickness=15, len=0.6, y=-0.29, title_font=dict(size=30), tickfont=dict(size=18)))\n","      plt.figure(dpi=1000)\n","      fig.update_traces(marker=dict(size=data_frame[size_point_representation], symbol='circle', line=dict( width=2, color='black'), opacity=1))\n","      return fig\n","\n","\n","   def calculate_size_point (descriptor):\n","        '''\n","        Funtion designed to generate the normalized values needed to visualize them in the size point\n","\n","        Arg:\n","        descriptor(str): Name of drug-likeness descriptors\n","\n","        Returns:\n","        Narmalized value of the drug-likeness descriptors\n","        '''\n","        return 7+np.log1p((descriptor - descriptor.min()) / (descriptor.max() - descriptor.min()))*12\n","\n","\n","\n","\n","\n","   def calculate_similarity_correlation(original_space:pd.DataFrame, reduced_space:pd.DataFrame, metric='euclidean'):\n","\n","        '''\n","        Calculates the correlation of pairwise similarities between the original and reduced spaces.\n","\n","        Args:\n","          original_space: pd.DataFrame of shape (n_compounds, n_features)\n","          reduced_space: pd.DataFrame (n_compounds, n_components)\n","          metric(str): The distance metric to compute pairwise distances.\n","\n","        Returns:\n","          correlation(float): The correlation between the original and reduced spaces. Values close to 1 indicare a strong preservation of relationships in the reduced space.\n","\n","        '''\n","\n","        original_distances = pairwise_distances(original_space, metric=metric)\n","        reduced_distances = pairwise_distances(reduced_space, metric=metric)\n","\n","        original_flat = original_distances[np.triu_indices_from(original_distances, k=1)]\n","        reduced_flat = reduced_distances[np.triu_indices_from(reduced_distances, k=1)]\n","\n","        correlation,_= pearsonr(original_flat, reduced_flat)\n","\n","        return correlation\n","\n","\n","\n","   def signaturizer_calculation(smiles_list:pd.DataFrame, signaturizer_code:list)->pd.DataFrame:\n","\n","        \"\"\"\n","        Calculation of the chemical signature from a list of SMILES.\n","\n","        Args:\n","            smiles_list (df): List of SMILES to process.\n","            signaturizer_code (list): Selected chemical signature code for calculation.\n","\n","        Returns:\n","            signature_df: DataFrame containing the calculated chemical signature.\n","        \"\"\"\n","\n","        signaturizer_mapping = {'A1': CCSpace.A1, 'A2': CCSpace.A2, 'A3': CCSpace.A3, 'A4': CCSpace.A4, 'A5': CCSpace.A5,\n","                                'B1': CCSpace.B1, 'B2': CCSpace.B2, 'B3': CCSpace.B3, 'B4': CCSpace.B4, 'B5': CCSpace.B5,\n","                                'C1': CCSpace.C1, 'C2': CCSpace.C2, 'C3': CCSpace.C3, 'C4': CCSpace.C4, 'C5': CCSpace.C5,\n","                                'D1': CCSpace.B1, 'D2': CCSpace.B2, 'D3': CCSpace.B3, 'D4': CCSpace.B4, 'D5': CCSpace.B5,\n","                                'E1': CCSpace.E1, 'E2': CCSpace.E2, 'E3': CCSpace.E3, 'E4': CCSpace.E4, 'E5': CCSpace.E5}\n","        if signaturizer_code not in signaturizer_mapping:\n","            raise ValueError(f\"Invalid signaturizer code: {signaturizer_code}\")\n","        signaturizer = Signaturizer(signaturizer_mapping[signaturizer_code])\n","        signature = signaturizer.infer_from_smiles(smiles_list)\n","        signature_df = pd.DataFrame(signature)\n","        return signature_df\n","\n","\n","   if signaturizer_code is None:\n","      signaturizer_code =[]\n","\n","   signaturizer_name = {'A1':'2D Fingerprints', 'A2':'3D Fingerprints', 'A3':'Scaffolds', 'A4':'Structural keys', 'A5':'Physicochemistry',\n","                      'B1':'Mechanisms of action', 'B2':'Metabolic genes', 'B3':'Crystals', 'B4':'Binding', 'B5':'HTS Bioassays',\n","                      'C1':'Small molecule roles', 'C2':'Small molecule pathways', 'C3':'Signaling pathways', 'C4':'Biological processes', 'C5':'Interactome',\n","                      'D1':'Transcription', 'D2':'Cancer cell lines', 'D3':'Chemical genetics', 'D4':'Morphology', 'D5':'Cell Bioassays',\n","                      'E1':'Therapeutic areas', 'E2':'Indications', 'E3':'Side Effects', 'E4':'Diseases and Toxicology', 'E5':'Drug-Drug Interactions'}\n","\n","   # Verification dataset is None\n","   if dataset is None:\n","      raise ValueError(\"The file name must be specified.\")\n","\n","   # Verification of the input dataset format\n","   file_readers = {\n","\n","    'csv': pd.read_csv,\n","    'xlsx': pd.read_excel,\n","    'tsv': lambda f: pd.read_csv(f, delimiter='\\t'),\n","    'json': pd.read_json,\n","    'xml': pd.read_xml\n","    }\n","\n","   ext = dataset.split('.')[-1].lower()\n","   if ext not in file_readers:\n","      raise ValueError(\"Unsupported file format\")\n","   # Read the dataset\n","   input_df = file_readers[ext](dataset)\n","\n","   # Validation of required columns in the Dataframe\n","   if ID not in input_df.columns:\n","    raise ValueError(f\"Error: The column {ID}, is missing in the provided  dataset\")\n","\n","   if smiles_column_name not in input_df.columns:\n","      raise ValueError(f\"Error: The column {smiles_column_name}, is missing in the provided  dataset\")\n","\n","   missing_columns = set(target_activities) - set(input_df.columns)\n","   if missing_columns:\n","      raise ValueError(f\"Error: The following target activities are missing in the provided dataset: {', '.join(missing_columns)}\")\n","\n","   # Validate types of variables\n","   if not isinstance(vPCA, bool):\n","      raise ValueError(\"Error: vPCA should be a boolean value (True or False)\")\n","\n","   if not isinstance(t_SNE, bool):\n","      raise ValueError(\"Error: t-SNE should be a boolean value (True or False)\")\n","\n","   if not isinstance(MACCS, bool):\n","      raise ValueError(\"Error: MACCS should be a boolean value (True or False)\")\n","\n","   if not isinstance(ECFP, bool):\n","      raise ValueError(\"Error: ECFP should be a boolean value (True or False)\")\n","\n","   if not isinstance(radius, int) or radius not in [2, 3]:\n","      raise ValueError(\"Error: radius should be an integer value of 2 or 3\")\n","\n","   if not isinstance(druglikeness_descriptors, bool):\n","      raise ValueError(\"Error: druglikeness_descriptors should be a boolean value (True or False)\")\n","\n","   if not isinstance(perplexity, int) or perplexity <= 0:\n","      raise ValueError(\"Error: perplexity should be an positive integer value\")\n","\n","   valid_signaturizer_codes = ['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5']\n","\n","   if not all(code in valid_signaturizer_codes for code in signaturizer_code):\n","    invalid_codes = [code for code in signaturizer_code if code not in valid_signaturizer_codes]\n","    raise ValueError(f\"Error: Invalid signaturizer code(s): {', '.join(invalid_codes)}\")\n","\n","   if not isinstance(size_point, float) or size_point <= 0:\n","      raise ValueError(\"Error: size_point should be a positive float value\")\n","\n","   if not isinstance(point_shape, str):\n","      raise ValueError(\"Error: point_shape should be a string value\")\n","\n","   # It always necessary at least one dimensionality reduction technique\n","\n","   if not vPCA and not t_SNE:\n","       raise Warning('Warning: Both PCA and t-SNE are disable. You May want to enable at least one for similarity calculations')\n","\n","   # Check for null values in key columns\n","   if input_df[smiles_column_name].isnull().any():\n","    raise ValueError(\"Error: The SMILES column contains null values. Please clean the data\")\n","\n","   if input_df[ID].isnull().any():\n","    raise ValueError(\"Error: The ID column contains null values. Pleas clean the data\")\n","\n","   # Check that ID is unique\n","   if not input_df[ID].is_unique:\n","    raise ValueError(\"Error: The ID column contains duplicate values. Please clean the data\")\n","\n","   # Validate target activities: check if values are numeric and non-null\n","   for activity in target_activities:\n","    if input_df[activity].isnull().any():\n","      raise ValueError(f'Error: The {activity} column contains null values. Please clean the data')\n","    if not pd.api.types.is_numeric_dtype(input_df[activity]):\n","      raise TypeError(f'Error: The {activity} column contains non-numeric values. Please ensure all values are numeric')\n","\n","\n","   # Definition of functions to processing SMILES\n","   STD = Standardizer()\n","   LFC = LargestFragmentChooser()\n","   UC = Uncharger()\n","   RI = Reionizer()\n","   TC = TautomerCanonicalizer()\n","\n","   Magenta_color = '\\033[95m'\n","   Default_color = '\\033[0m'\n","\n","   # Prossesing of Smiles and evaluation of activities\n","   #input_df = parallel_pretreatment(data_frame=input_df, smiles_column_name=smiles_column_name)\n","   #input_df = input_df.drop_duplicates(subset=['Canonical_Smiles'], keep='first').reset_index(drop=True)\n","   input_df['mpIC50_value'] = -np.log10(input_df[target_activities]).mean(axis=1)\n","   max_value = input_df['mpIC50_value'].max()\n","   min_value = input_df['mpIC50_value'].min()\n","   input_df['std'] = input_df[target_activities].std(axis=1)\n","   input_df['norma'] = ((input_df['std'] - input_df['std'].min()) / (input_df['std'].max() - input_df['std'].min()))\n","   input_df['normal_desviation'] = input_df['norma'] * (size_point-10)+9\n","   input_df['normal_desviation'] = input_df['normal_desviation'].fillna(10)\n","\n","   input_df = input_df.rename(columns={'Smiles': 'Canonical_Smiles'})\n","\n","   # Calcualtion of descriptors\n","   smiles_list = input_df[[ID,\"Canonical_Smiles\"]]\n","   smiles_mols = [Chem.MolFromSmiles(x) for x in smiles_list[\"Canonical_Smiles\"]]\n","   descriptors_df = pd.DataFrame({\n","            \"HBA\": [Descriptors.NumHAcceptors(mol) for mol in smiles_mols],\n","            \"MW\": [Descriptors.MolWt(mol) for mol in smiles_mols],\n","            \"HBD\": [Descriptors.NumHDonors(mol) for mol in smiles_mols],\n","            \"RB\": [Descriptors.NumRotatableBonds(mol) for mol in smiles_mols],\n","            \"LogP\": [Descriptors.MolLogP(mol) for mol in smiles_mols],\n","            \"TPSA\": [Descriptors.TPSA(mol) for mol in smiles_mols]\n","        }, index=smiles_list.index)\n","\n","   descriptors_df['Canonical_Smiles'] = smiles_list['Canonical_Smiles']\n","   input_df = pd.merge(input_df, descriptors_df, on='Canonical_Smiles', how='inner')\n","\n","\n","   for descriptor in ['HBA', 'LogP', 'TPSA', 'MW', 'HBD', 'RB']:\n","    input_df[f'size_point_{descriptor}'] = calculate_size_point(descriptors_df[descriptor])\n","\n","   input_df = evaluate_metric(input_df, evaluation_metric=evaluation_metric, metric_name=metric_name)\n","\n","   pd.DataFrame(input_df).to_csv('input_df.csv')\n","\n","   # If MACCS keys are selected by the user, this section will build a matrix to calculate the similarity\n","   if MACCS is True:\n","\n","              matrix_MACCS_df = calculate_all_similarities_blocks(fp_type='MACCS', method='tanimoto')\n","              data_MACCS = matrix_MACCS_df.iloc[:,0:].values\n","\n","              # If user select PCA, this section will recover the values of similarity and train the model to calcualte principal componentes\n","              if vPCA is True:\n","\n","                    pca_results_MACCS, exp_var_pca_maccs = applying_pca(data_MACCS)\n","\n","                    data_MACCS_PCA = pd.DataFrame({ID:input_df[ID], 'Canonical_Smiles': input_df['Canonical_Smiles'], 'component1':pca_results_MACCS[:,0], 'component2':pca_results_MACCS[:,1]})\n","\n","                    loadings_maccs = pca_results_MACCS[:,:2]**2\n","                    loadings_maccs = loadings_maccs / loadings_maccs.sum(axis=0)\n","\n","                    dataset_MACCS_PCA= pd.merge(data_MACCS_PCA, input_df, on=(\"Canonical_Smiles\", ID), how='inner')\n","                    dataset_MACCS_PCA[['PC1 contribution', 'PC2 contribution']] = loadings_maccs\n","\n","                    # Calculate Trustworthiness and Correlation metrics using result of similarity calculation and pca results\n","                    trust_pca_maccs = trustworthiness(data_MACCS, pca_results_MACCS)\n","                    correlation_pca_maccs = (calculate_similarity_correlation(data_MACCS, pca_results_MACCS))\n","\n","                    print(f'Trustworthiness: {Magenta_color}{trust_pca_maccs:3f}{Default_color}')\n","                    print(f'Correlation: {Magenta_color}{correlation_pca_maccs:3f}{Default_color}')\n","\n","                    dataset_MACCS_PCA.to_csv('dataset_MACCS_PCA.csv')\n","                    x_label = f'component1 {exp_var_pca_maccs[0]}'\n","                    y_label = f'component2 {exp_var_pca_maccs[1]}'\n","\n","                    # This section creates and customizes a scatter plot, generating an interactive plot and producing a downloadable file with higher resolution.\n","                    fig_pca = px.scatter(dataset_MACCS_PCA, x='component1', y='component2', color=metric_name, color_continuous_scale=palette, title='PCA - MACCS',\n","                      labels={'component1': f'Component 1 ({exp_var_pca_maccs[0]*100:.3}%)', 'component2': f'Component 2 ({exp_var_pca_maccs[1]*100:.3}%)'},\n","                      width=1200,\n","                      height=900,\n","                      #range_color=[min_value, max_value]\n","                                         )\n","                    fig_pca = configure_plot_layout(fig_pca, data_frame=dataset_MACCS_PCA, size_point_representation=size_point_representation)\n","                    pio.write_image(fig_pca, 'fig_PCA_MACCS.png')\n","                    app_maker_maccs_pca = molplotly.add_molecules(fig=fig_pca, df=dataset_MACCS_PCA, smiles_col=\"Canonical_Smiles\", title_col=ID, color_col=metric_name, caption_cols=['Canonical_Smiles', 'PC1 contribution', 'PC2 contribution'])\n","                    serve_kernel_port_as_iframe(\"localhost\")\n","                    app_maker_maccs_pca.run(port=8060)\n","                    #fig_pca.show()\n","\n","\n","\n","              # \"If the user sets the variable t_SNE to true, this section will retrieve similarity calculation values to train the model. It is necessary to define the perplexity value according to the dataset size\n","              if t_SNE is True:\n","\n","                      tsne_results_MACCS = applying_tsne(data_MACCS, perplexity=perplexity, n_iterations=n_iterations)\n","\n","                      all_dataset_tSNE = pd.DataFrame({ID:input_df[ID], 'Canonical_Smiles':input_df['Canonical_Smiles'], 'axis 1':tsne_results_MACCS[:,0], 'axis 2':tsne_results_MACCS[:,1]})\n","\n","                      all_dataset_tSNE = pd.merge(all_dataset_tSNE, input_df, on=(\"Canonical_Smiles\", ID), how='inner')\n","\n","                      all_dataset_tSNE.to_csv('dataset_tSNE_MACCS.csv')\n","\n","                      # Calculate Trustworthiness and Correlation metrics using result of similarity calculation and tsne resulta\n","                      trust_tsne_maccs = trustworthiness(data_MACCS, tsne_results_MACCS)\n","                      correlation_tsne_maccs = (calculate_similarity_correlation(data_MACCS, tsne_results_MACCS))\n","                      print(f'Trustworthiness: {Magenta_color}{trust_tsne_maccs:3f}{Default_color}')\n","                      print(f'Correlation: {Magenta_color}{correlation_tsne_maccs:3f}{Default_color}')\n","\n","\n","                      # Plot construction\n","                      fig_tsne_MACCS = px.scatter(all_dataset_tSNE, x='axis 1', y='axis 2', color=metric_name, color_continuous_scale=palette, title='T-SNE - MACCS',\n","                      labels={'axis 1': 'Component 1', 'axis 2': 'Component 2'},\n","                      width=1200,\n","                      height=900,\n","                      #range_color=[min_value, max_value]\n","                                                  )\n","                      fig_tsne_MACCS = configure_plot_layout(fig_tsne_MACCS, data_frame=all_dataset_tSNE, size_point_representation=size_point_representation)\n","                      pio.write_image(fig_tsne_MACCS, 'fig_tsne_MACCS.png')\n","                      app_maker_maccs_tsne = molplotly.add_molecules(fig=fig_tsne_MACCS, df=all_dataset_tSNE, smiles_col=\"Canonical_Smiles\", title_col=ID, color_col=metric_name, caption_cols=['Canonical_Smiles'])\n","                      #fig_tsne_MACCS.show()\n","                      serve_kernel_port_as_iframe(\"localhost\")\n","                      app_maker_maccs_tsne.run(port=8062)\n","\n","\n","\n","  # If the user sets ECFP to true, this section will retrieve similarity_calc to generate a similarity matrix using the Extended Connectivity Fingerprint(ECFP). It is necessary to specify the radius to calculate either ECFP4 or ECFP6\n","   if ECFP is True:\n","\n","               matrix_ECFP_df = calculate_all_similarities_blocks(fp_type='ECFP', method='tanimoto')\n","               data_ECFP = matrix_ECFP_df.iloc[:,0:].values\n","\n","                # This section performs PCA model training and calculates the principal components.\n","               if vPCA is True:\n","\n","                      pca_results_ECFP, exp_var_pca_ecfp = applying_pca(data_ECFP)\n","\n","                      data_ECFP_PCA = pd.DataFrame({ID:input_df[ID], 'Canonical_Smiles': input_df['Canonical_Smiles'], 'component1':pca_results_ECFP[:,0], 'component2':pca_results_ECFP[:,1]})\n","\n","                      loadings_ecfp = pca_results_ECFP[:,:2]**2\n","                      loadings_ecfp = loadings_ecfp / loadings_ecfp.sum(axis=0)\n","\n","                      dataset_ECFP_PCA= pd.merge(data_ECFP_PCA, input_df, on=(\"Canonical_Smiles\", ID), how='inner')\n","                      dataset_ECFP_PCA[['PC1 contribution', 'PC2 contribution']] = loadings_ecfp\n","\n","\n","                      # Calculate Trustworthiness and Correlation metrics using result of similarity calculation and pca results\n","                      trust_pca_ecfp = trustworthiness(data_ECFP, pca_results_ECFP)\n","                      correlation_pca_ecfp = (calculate_similarity_correlation(data_ECFP, pca_results_ECFP))\n","\n","                      print(f'Trustworthiness: {Magenta_color}{trust_pca_ecfp:3f}{Default_color}')\n","                      print(f'Correlation: {Magenta_color}{correlation_pca_ecfp:3f}{Default_color}')\n","\n","\n","                      dataset_ECFP_PCA.to_csv('dataset_ECFP_PCA.csv')\n","                      x_label = f'component1 {exp_var_pca_ecfp[0]}'\n","                      y_label = f'component2 {exp_var_pca_ecfp[1]}'\n","\n","                      # Plot configuration\n","                      fig_pca_ECFP = px.scatter(dataset_ECFP_PCA, x='component1', y='component2', color=metric_name, color_continuous_scale=palette, title='PCA - ECFP',\n","                       labels={'component1': f'Component 1 ({exp_var_pca_ecfp[0]*100:.3}%)', 'component2': f'Component 2 ({exp_var_pca_ecfp[1]*100:.3}%)'},\n","                       width=1200,\n","                       height=900,\n","                       #range_color=[min_value, max_value]\n","                                                )\n","                      fig_pca_ECFP = configure_plot_layout(fig_pca_ECFP, data_frame=dataset_ECFP_PCA, size_point_representation=size_point_representation)\n","                      pio.write_image( fig_pca_ECFP, 'fig_PCA_ECFP.png')\n","                      app_maker_ecfp_pca = molplotly.add_molecules(fig=fig_pca_ECFP, df=dataset_ECFP_PCA, smiles_col=\"Canonical_Smiles\", title_col=ID, color_col=metric_name, caption_cols=['Canonical_Smiles', 'PC1 contribution', 'PC2 contribution'])\n","                      #fig_pca_ECFP.show()\n","                      serve_kernel_port_as_iframe(\"localhost\")\n","                      app_maker_ecfp_pca.run(port=8061)\n","\n","\n","\n","                # t-SNE technique application with ECFP similarity calculation\n","               if t_SNE is True:\n","\n","                      tsne_results_ECFP = applying_tsne(data_ECFP, perplexity=perplexity, n_iterations=n_iterations)\n","\n","                      dataset_tSNE_ECFP = pd.DataFrame({ID:input_df[ID], 'Canonical_Smiles': input_df['Canonical_Smiles'], 'axis 1':tsne_results_ECFP[:,0], 'axis 2':tsne_results_ECFP[:,1]})\n","\n","                      dataset_tSNE_ECFP = pd.merge(dataset_tSNE_ECFP, input_df, on=(\"Canonical_Smiles\", ID), how='inner')\n","\n","                      dataset_tSNE_ECFP.to_csv('dataset_tSNE_ECFP.csv')\n","\n","                      # Calculate Trustworthiness and Correlation metrics using result of similarity calculation and pca results\n","                      trust_tsne_ecfp = trustworthiness(data_ECFP, tsne_results_ECFP)\n","                      correlation_tsne_ecfp = (calculate_similarity_correlation(data_ECFP, tsne_results_ECFP))\n","\n","                      print(f'Trustworthiness: {Magenta_color}{trust_tsne_ecfp:3f}{Default_color}')\n","                      print(f'Correlation: {Magenta_color}{correlation_tsne_ecfp:3f}{Default_color}')\n","\n","                      # Plot configuration\n","                      fig_tsne_ECFP = px.scatter(dataset_tSNE_ECFP, x='axis 1', y='axis 2', color=metric_name, color_continuous_scale=palette, title='T-SNE - ECFP', labels={'axis 1': 'Component 1', 'axis 2': 'Component 2'},\n","                       width=1200,\n","                       height=900,\n","                       #range_color=[min_value, max_value]\n","                                                 )\n","                      fig_tsne_ECFP = configure_plot_layout(fig_tsne_ECFP, data_frame=dataset_tSNE_ECFP, size_point_representation=size_point_representation)\n","                      pio.write_image( fig_tsne_ECFP, 'fig_tsne_ECFP.png')\n","                      app_maker_ecfp_tsne = molplotly.add_molecules(fig=fig_tsne_ECFP, df=dataset_tSNE_ECFP, smiles_col=\"Canonical_Smiles\", title_col=ID, color_col=metric_name, caption_cols=['Canonical_Smiles'])\n","                      #fig_tsne_ECFP.show()\n","                      serve_kernel_port_as_iframe(\"localhost\")\n","                      app_maker_ecfp_tsne.run(port=8064)\n","\n","\n","\n","   # This section calcualte Hidrogen Bond Aceptor(HBA), Hidrogen Bond Donator(HBD), Partitipon Coeficient(LogP), Total Polar Surface Area(TPSA), Molecular Weight(MW), Rotable Bonds(RB) descriptors form the processed SMILES\n","   if druglikeness_descriptors is True:\n","          smiles_list = pd.merge(smiles_list, descriptors_df, on='Canonical_Smiles', how='inner')\n","          descriptors_values = smiles_list.iloc[:,2:6].values\n","          molecular_descriptors_data_std = StandardScaler().fit_transform(descriptors_values) #Scaling of descriptor values\n","          df_MD = pd.DataFrame(molecular_descriptors_data_std)\n","\n","          # Recover the DataFrame with scaled descriptor values to train the model and combine the ID, SMILES, and principal components into a single DataFrame.\n","          if vPCA is True:\n","\n","              pca_results_druglikeness, explained_variance_druglikeness =  applying_pca(molecular_descriptors_data_std)\n","\n","              dataset_druglikeness_pca = pd.DataFrame({ID:input_df[ID], 'Canonical_Smiles': input_df['Canonical_Smiles'], 'component1':pca_results_druglikeness[:,0], 'component2':pca_results_druglikeness[:,1]})\n","\n","              loadings_druglikeness = pca_results_druglikeness[:,:2]**2\n","              loadings_druglikeness = loadings_druglikeness / loadings_druglikeness.sum(axis=0)\n","\n","              dataset_druglikeness_pca[['PC1 contribution', 'PC2 contribution']] = loadings_druglikeness\n","\n","\n","              dataset_druglikeness_pca= pd.merge(dataset_druglikeness_pca, input_df, on=(\"Canonical_Smiles\", ID), how='inner')\n","\n","              # Calculate Trustworthiness and Correlation metrics using result of similarity calculation and pca results\n","              trust_pca_druglikeness = trustworthiness(molecular_descriptors_data_std, pca_results_druglikeness)\n","              correlation_pca_druglikeness = (calculate_similarity_correlation(molecular_descriptors_data_std, pca_results_druglikeness))\n","              print(f'Trustworthiness: {Magenta_color}{trust_pca_druglikeness:3f}{Default_color}')\n","              print(f'Correlation: {Magenta_color}{correlation_pca_druglikeness:3f}{Default_color}')\n","\n","              dataset_druglikeness_pca.to_csv('dataset_druglikeness_PCA.csv')\n","              x_label = f'component1 {explained_variance_druglikeness[0]}'\n","              y_label = f'component2 {explained_variance_druglikeness[1]}'\n","\n","              # Plot configuration\n","              fig_pca_druglikeness = px.scatter(dataset_druglikeness_pca, x='component1', y='component2', color=metric_name, color_continuous_scale=palette, title='PCA - Drug-likeness descriptors', labels={'component1': f'Component 1 ({explained_variance_druglikeness[0]*100:.3}%)', 'component2': f'Component 2 ({explained_variance_druglikeness[1]*100:.3}%)'},\n","                 width=1200,\n","                 height=900\n","                 #range_color=[min_value, max_value]\n","                                                )\n","              fig_pca_druglikeness = configure_plot_layout(fig_pca_druglikeness, data_frame=dataset_druglikeness_pca, size_point_representation=size_point_representation)\n","              pio.write_image( fig_pca_druglikeness, 'fig_pca_druglikeness.png')\n","              app_maker = molplotly.add_molecules(fig= fig_pca_druglikeness, df=dataset_druglikeness_pca, smiles_col=\"Canonical_Smiles\", title_col=ID, color_col=metric_name, caption_cols=['Canonical_Smiles', 'HBA', 'LogP', 'TPSA', 'MW', 'HBD', 'RB', 'PC1 contribution', 'PC2 contribution'])\n","              #fig_pca_MD.show()\n","              serve_kernel_port_as_iframe(\"localhost\")\n","              app_maker.run(port=8066)\n","\n","\n","          # run the t_SNE model with scaled descriptors values\n","          if t_SNE is True:\n","\n","                tsne_results_MD = applying_tsne(molecular_descriptors_data_std, perplexity=perplexity, n_iterations=n_iterations)\n","\n","                dataset_tSNE_MD = pd.DataFrame({ID:input_df[ID], 'Canonical_Smiles': input_df['Canonical_Smiles'], 'axis 1':tsne_results_MD[:,0], 'axis 2':tsne_results_MD[:,1]})\n","\n","\n","                dataset_tSNE_MD = pd.merge(dataset_tSNE_MD, input_df, on=(\"Canonical_Smiles\", ID), how='inner')\n","\n","\n","                dataset_tSNE_MD.to_csv('dataset_druglikeness_tSNE.csv')\n","\n","                # Calculate Trustworthiness and Correlation metrics using result of similarity calculation and pca results\n","                trust_tsne_druglikeness = trustworthiness(molecular_descriptors_data_std, tsne_results_MD)\n","                correlation_tsne_druglikeness = (calculate_similarity_correlation(molecular_descriptors_data_std, tsne_results_MD))\n","                print(f'Trustworthiness: {Magenta_color}{trust_tsne_druglikeness:3f}{Default_color}')\n","                print(f'Correlation: {Magenta_color}{correlation_tsne_druglikeness:3f}{Default_color}')\n","\n","                # Plot configuration\n","                fig_tsne_druglikeness = px.scatter(dataset_tSNE_MD, x='axis 1', y='axis 2', color=metric_name, color_continuous_scale=palette, title='T-SNE - Drug-likeness descriptors', labels={'axis 1': 'Component 1', 'axis 2': 'Component 2'},\n","                  width=1200,\n","                  height=900,\n","                  #range_color=[min_value, max_value]\n","                                                   )\n","                fig_tsne_druglikeness = configure_plot_layout(fig_tsne_druglikeness, data_frame=dataset_tSNE_MD, size_point_representation=size_point_representation)\n","                pio.write_image(fig_tsne_druglikeness, 'fig_tsne_druglikeness.png')\n","                app_maker = molplotly.add_molecules(fig=fig_tsne_druglikeness, df=dataset_tSNE_MD, smiles_col=\"Canonical_Smiles\", title_col=ID, color_col=metric_name, caption_cols=['Canonical_Smiles'])\n","                #fig_tsne_MD.show()\n","                serve_kernel_port_as_iframe(\"localhost\")\n","                app_maker.run(port=8068)\n","\n","\n","\n","   # If user decicde to obtein bioactive descriptors, this section will recovery the signaturizer_calcualtion funtion to build a dataframe with the values of the signaturizes selectioned\n","   if signaturizer_code is not None:\n","    !pip install signaturizer3d --no-deps\n","    from signaturizer3d import Signaturizer, CCSpace\n","\n","    for code in signaturizer_code:\n","      smiles = input_df[[ID,'Canonical_Smiles']]\n","      signature_df = signaturizer_calculation(smiles_list=smiles['Canonical_Smiles'], signaturizer_code = code)\n","\n","\n","      # With signaturizer fingerprint we train PCA model\n","      if vPCA is True:\n","\n","              pca_results_signatures, explained_variance_signatures = applying_pca(signature_df)\n","\n","              dataset_signatures_pca = pd.DataFrame({ID:input_df[ID], 'Canonical_Smiles': input_df['Canonical_Smiles'], 'component1':pca_results_signatures[:,0], 'component2':pca_results_signatures[:,1]})\n","\n","              loadings_signatures = pca_results_signatures[:,:2]**2\n","              loadings_signatures = loadings_signatures / loadings_signatures.sum(axis=0)\n","\n","              dataset_signatures_pca[['PC1 contribution', 'PC2 contribution']] = loadings_signatures\n","\n","              dataset_signatures_pca= pd.merge(dataset_signatures_pca, input_df, on=(\"Canonical_Smiles\", ID), how='inner')\n","\n","              dataset_signatures_pca[['PC1 contribution', 'PC2 contribution']] = loadings_signatures\n","\n","              # Calculate Trustworthiness and Correlation metrics using result of similarity calculation and pca results\n","              trust_pca_signatures = trustworthiness(signature_df, pca_results_signatures)\n","              correlation_pca_signatures = (calculate_similarity_correlation(signature_df, pca_results_signatures))\n","\n","              print(f'Trustworthiness: {Magenta_color}{trust_pca_signatures:3f}{Default_color}')\n","              print(f'Correlation: {Magenta_color}{correlation_pca_signatures:3f}{Default_color}')\n","\n","              dataset_signatures_pca.to_csv(f'dataset_{code}_PCA.csv')\n","              x_label = f'component1 {explained_variance_signatures[0]}'\n","              y_label = f'component2 {explained_variance_signatures[1]}'\n","\n","              # Plot configuration\n","              fig_pca_mechanisim = px.scatter(dataset_signatures_pca, x='component1',y='component2', color=metric_name, color_continuous_scale=palette, title=(f'PCA - {signaturizer_name.get(code)}'), labels={'component1': f'Component 1 ({explained_variance_signatures[0]*100:.3}%)', 'component2': f'Component 2 ({explained_variance_signatures[1]*100:.3}%)'},\n","               width=1200,\n","               height=900,\n","               #range_color=[min_value, max_value]\n","                                              )\n","              fig_pca_mechanisim = configure_plot_layout(fig_pca_mechanisim, data_frame=dataset_signatures_pca, size_point_representation=size_point_representation)\n","              pio.write_image(fig_pca_mechanisim, f'fig_pca_{signaturizer_name.get(code)}.png')\n","              app_maker = molplotly.add_molecules(fig=fig_pca_mechanisim, df=dataset_signatures_pca, smiles_col=\"Canonical_Smiles\", title_col=ID, color_col=metric_name, caption_cols=['Canonical_Smiles', 'PC1 contribution', 'PC2 contribution'])\n","              #fig_pca_mechanisim.show()\n","              serve_kernel_port_as_iframe(\"localhost\")\n","              app_maker.run(port=8070)\n","\n","      # Run t_SNE model to signaturizer fingerprint\n","      if t_SNE is True:\n","\n","                tsne_results_signatures = applying_tsne(signature_df, n_iterations=n_iterations, perplexity=perplexity)\n","\n","                dataset_tSNE_signatures = pd.DataFrame({ID:input_df[ID], 'Canonical_Smiles': input_df['Canonical_Smiles'], 'axis 1':tsne_results_signatures[:,0], 'axis 2':tsne_results_signatures[:,1]})\n","\n","                dataset_tSNE_signatures = pd.merge(dataset_tSNE_signatures, input_df, on=(\"Canonical_Smiles\", ID), how='inner')\n","\n","                dataset_tSNE_signatures.to_csv(f'dataset_{code}_tSNE.csv')\n","\n","                # Calculate Trustworthiness and Correlation metrics using result of similarity calculation and pca results\n","                trust_tsne_signatures = trustworthiness(signature_df, tsne_results_signatures)\n","                correlation_tsne_signatures = (calculate_similarity_correlation(signature_df, tsne_results_signatures))\n","                print(f'Trustworthiness: {Magenta_color}{trust_tsne_signatures:3f}{Default_color}')\n","                print(f'Correlation: {Magenta_color}{correlation_tsne_signatures:3f}{Default_color}')\n","\n","                # Plot config\n","                fig_tsne_signaturizer = px.scatter(dataset_tSNE_signatures, x='axis 1', y='axis 2', color=metric_name, color_continuous_scale=palette, title=(f't-SNE - {signaturizer_name.get(code)}'), labels={'axis 1': 'Component 1', 'axis 2': 'Component 2'},\n","                    width=1200,\n","                    height=900,\n","                    #range_color=[min_value, max_value]\n","                                                   )\n","                fig_tsne_signaturizer = configure_plot_layout(fig_tsne_signaturizer, data_frame=dataset_tSNE_signatures, size_point_representation=size_point_representation)\n","                pio.write_image(fig_tsne_signaturizer, f'fig_tsne_{signaturizer_name.get(code)}.png')\n","                app_maker = molplotly.add_molecules(fig=fig_tsne_signaturizer, df=dataset_tSNE_signatures, smiles_col=\"Canonical_Smiles\", title_col=ID, color_col=metric_name, caption_cols=['Canonical_Smiles'])\n","                #fig_tsne_signaturizer.show()\n","                serve_kernel_port_as_iframe(\"localhost\")\n","                app_maker.run(port=8072)\n","\n","   if MAP4 is True:\n","\n","               smiles_list = input_df[\"Canonical_Smiles\"].tolist()\n","               map_4 = MAPFingerprint()\n","               fingerprints_map4 = map_4.transform(smiles_list)\n","               fps_bitvect = [numpy_to_bitvect(fp) for fp in fingerprints_map4]\n","               data_MAP4 = map4_tanimoto_calculation(fps_bitvect)\n","\n","\n","              # This section performs PCA model training and calculates the principal components.\n","               if vPCA is True:\n","\n","                      pca_results_MAP4, exp_var_pca_MAP4 = applying_pca(data_MAP4)\n","\n","                      data_MAP4_PCA = pd.DataFrame({ID:input_df[ID], 'Canonical_Smiles': input_df['Canonical_Smiles'], 'component1':pca_results_MAP4[:,0], 'component2':pca_results_MAP4[:,1]})\n","\n","                      loadings_MAP4 = pca_results_MAP4[:, :2]**2\n","                      loadings_MAP4 = loadings_MAP4 / loadings_MAP4.sum(axis=0)\n","\n","                      dataset_MAP4_PCA= pd.merge(data_MAP4_PCA, input_df, on=(\"Canonical_Smiles\", ID), how='inner')\n","                      dataset_MAP4_PCA = dataset_MAP4_PCA.iloc[:loadings_MAP4.shape[0]]\n","                      dataset_MAP4_PCA.to_csv('dataset_MAP4_PCA.csv')\n","                      dataset_MAP4_PCA[['PC1 contribution', 'PC2 contribution']] = loadings_MAP4\n","\n","\n","\n","                      # Calculate Trustworthiness and Correlation metrics using result of similarity calculation and pca results\n","                      trust_pca_MAP4 = trustworthiness(data_MAP4, pca_results_MAP4)\n","                      correlation_pca_MAP4 = (calculate_similarity_correlation(data_MAP4, pca_results_MAP4))\n","                      print(f'Trustworthiness: {Magenta_color}{trust_pca_MAP4:3f}{Default_color}')\n","                      print(f'Correlation: {Magenta_color}{correlation_pca_MAP4:3f}{Default_color}')\n","\n","\n","                      dataset_MAP4_PCA.to_csv('dataset_MAP4_PCA.csv')\n","                      x_label = f'component1 {exp_var_pca_MAP4[0]}'\n","                      y_label = f'component2 {exp_var_pca_MAP4[1]}'\n","\n","                      # Plot configuration\n","                      fig_pca_MAP4 = px.scatter(dataset_MAP4_PCA, x='component1', y='component2', color=metric_name, color_continuous_scale=palette, title='PCA - MAP4',\n","                       labels={'component1': f'Component 1 ({exp_var_pca_MAP4[0]*100:.3}%)', 'component2': f'Component 2 ({exp_var_pca_MAP4[1]*100:.3}%)'},\n","                       width=1200,\n","                       height=900,\n","                       #range_color=[min_value, max_value]\n","                                                )\n","                      fig_pca_MAP4 = configure_plot_layout(fig_pca_MAP4, data_frame=dataset_MAP4_PCA, size_point_representation=size_point_representation)\n","                      pio.write_image( fig_pca_MAP4, 'fig_PCA_MAP4.png')\n","                      app_maker_MAP4_pca = molplotly.add_molecules(fig=fig_pca_MAP4, df=dataset_MAP4_PCA, smiles_col=\"Canonical_Smiles\", title_col=ID, color_col=metric_name, caption_cols=['Canonical_Smiles', 'PC1 contribution', 'PC2 contribution'])\n","                      #fig_pca_ECFP.show()\n","                      serve_kernel_port_as_iframe(\"localhost\")\n","                      app_maker_MAP4_pca.run(port=8061)\n","\n","\n","\n","                # t-SNE technique application with ECFP similarity calculation\n","               if t_SNE is True:\n","\n","                      tsne_results_MAP4 = applying_tsne(data_MAP4, perplexity=perplexity, n_iterations=n_iterations)\n","\n","                      dataset_tSNE_MAP4 = pd.DataFrame({ID:input_df[ID], 'Canonical_Smiles': input_df['Canonical_Smiles'], 'axis 1':tsne_results_MAP4[:,0], 'axis 2':tsne_results_MAP4[:,1]})\n","\n","                      dataset_tSNE_MAP4 = pd.merge(dataset_tSNE_MAP4, input_df, on=(\"Canonical_Smiles\", ID), how='inner')\n","\n","                      dataset_tSNE_MAP4.to_csv('dataset_tSNE_MAP4.csv')\n","\n","                      # Calculate Trustworthiness and Correlation metrics using result of similarity calculation and pca results\n","                      trust_tsne_MAP4 = trustworthiness(data_MAP4, tsne_results_MAP4)\n","                      correlation_tsne_MAP4 = (calculate_similarity_correlation(data_MAP4, tsne_results_MAP4))\n","                      print(f'Trustworthiness: {Magenta_color}{trust_tsne_MAP4:3f}{Default_color}')\n","                      print(f'Correlation: {Magenta_color}{correlation_tsne_MAP4:3f}{Default_color}')\n","\n","                      # Plot configuration\n","                      fig_tsne_MAP4 = px.scatter(dataset_tSNE_MAP4, x='axis 1', y='axis 2', color=metric_name, color_continuous_scale=palette, title='T-SNE - MAP4', labels={'axis 1': 'Component 1', 'axis 2': 'Component 2'},\n","                       width=1200,\n","                       height=900,\n","                       #range_color=[min_value, max_value]\n","                                                 )\n","                      fig_tsne_MAP4 = configure_plot_layout(fig_tsne_MAP4, data_frame=dataset_tSNE_MAP4, size_point_representation=size_point_representation)\n","                      pio.write_image( fig_tsne_MAP4, 'fig_tsne_MAP4.png')\n","                      app_maker_ecfp_MAP4 = molplotly.add_molecules(fig=fig_tsne_MAP4, df=dataset_tSNE_MAP4, smiles_col=\"Canonical_Smiles\", title_col=ID, color_col=metric_name, caption_cols=['Canonical_Smiles'])\n","                      #fig_tsne_ECFP.show()\n","                      serve_kernel_port_as_iframe(\"localhost\")\n","                      app_maker_ecfp_MAP4.run(port=8064)"]},{"cell_type":"markdown","metadata":{"id":"ztUoSR-YXN1x"},"source":["# Chemical multiverse"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"byx0TPnKbAsc","executionInfo":{"status":"ok","timestamp":1746473602148,"user_tz":360,"elapsed":337023,"user":{"displayName":"Israel Castañeda","userId":"17651928571784521078"}},"outputId":"87507501-c023-4628-b953-29c61fced8b6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/pandas/core/internals/blocks.py:393: RuntimeWarning: divide by zero encountered in log10\n","  result = func(self.values, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Trustworthiness: \u001b[95m0.988497\u001b[0m\n","Correlation: \u001b[95m0.999719\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dash/dash.py:587: UserWarning:\n","\n","JupyterDash is deprecated, use Dash instead.\n","See https://dash.plotly.com/dash-in-jupyter for more details.\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","    if (!google.colab.kernel.accessAllowed && !cache) {\n","      return;\n","    }\n","    element.appendChild(document.createTextNode(''));\n","    const url = await google.colab.kernel.proxyPort(port, {cache});\n","    const iframe = document.createElement('iframe');\n","    iframe.src = new URL(path, url).toString();\n","    iframe.height = height;\n","    iframe.width = width;\n","    iframe.style.border = 0;\n","    iframe.allow = [\n","        'accelerometer',\n","        'autoplay',\n","        'camera',\n","        'clipboard-read',\n","        'clipboard-write',\n","        'gyroscope',\n","        'magnetometer',\n","        'microphone',\n","        'serial',\n","        'usb',\n","        'xr-spatial-tracking',\n","    ].join('; ');\n","    element.appendChild(iframe);\n","  })(localhost, \"/\", \"100%\", \"400\", false, window.element)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","    if (!google.colab.kernel.accessAllowed && !cache) {\n","      return;\n","    }\n","    element.appendChild(document.createTextNode(''));\n","    const url = await google.colab.kernel.proxyPort(port, {cache});\n","    const iframe = document.createElement('iframe');\n","    iframe.src = new URL(path, url).toString();\n","    iframe.height = height;\n","    iframe.width = width;\n","    iframe.style.border = 0;\n","    iframe.allow = [\n","        'accelerometer',\n","        'autoplay',\n","        'camera',\n","        'clipboard-read',\n","        'clipboard-write',\n","        'gyroscope',\n","        'magnetometer',\n","        'microphone',\n","        'serial',\n","        'usb',\n","        'xr-spatial-tracking',\n","    ].join('; ');\n","    element.appendChild(iframe);\n","  })(8066, \"/\", \"100%\", 650, false, window.element)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Trustworthiness: \u001b[95m0.997376\u001b[0m\n","Correlation: \u001b[95m0.501023\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dash/dash.py:587: UserWarning:\n","\n","JupyterDash is deprecated, use Dash instead.\n","See https://dash.plotly.com/dash-in-jupyter for more details.\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","    if (!google.colab.kernel.accessAllowed && !cache) {\n","      return;\n","    }\n","    element.appendChild(document.createTextNode(''));\n","    const url = await google.colab.kernel.proxyPort(port, {cache});\n","    const iframe = document.createElement('iframe');\n","    iframe.src = new URL(path, url).toString();\n","    iframe.height = height;\n","    iframe.width = width;\n","    iframe.style.border = 0;\n","    iframe.allow = [\n","        'accelerometer',\n","        'autoplay',\n","        'camera',\n","        'clipboard-read',\n","        'clipboard-write',\n","        'gyroscope',\n","        'magnetometer',\n","        'microphone',\n","        'serial',\n","        'usb',\n","        'xr-spatial-tracking',\n","    ].join('; ');\n","    element.appendChild(iframe);\n","  })(localhost, \"/\", \"100%\", \"400\", false, window.element)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","    if (!google.colab.kernel.accessAllowed && !cache) {\n","      return;\n","    }\n","    element.appendChild(document.createTextNode(''));\n","    const url = await google.colab.kernel.proxyPort(port, {cache});\n","    const iframe = document.createElement('iframe');\n","    iframe.src = new URL(path, url).toString();\n","    iframe.height = height;\n","    iframe.width = width;\n","    iframe.style.border = 0;\n","    iframe.allow = [\n","        'accelerometer',\n","        'autoplay',\n","        'camera',\n","        'clipboard-read',\n","        'clipboard-write',\n","        'gyroscope',\n","        'magnetometer',\n","        'microphone',\n","        'serial',\n","        'usb',\n","        'xr-spatial-tracking',\n","    ].join('; ');\n","    element.appendChild(iframe);\n","  })(8068, \"/\", \"100%\", 650, false, window.element)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting signaturizer3d\n","  Downloading signaturizer3d-0.1.8-py3-none-any.whl.metadata (7.5 kB)\n","Downloading signaturizer3d-0.1.8-py3-none-any.whl (56 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: signaturizer3d\n","Successfully installed signaturizer3d-0.1.8\n","Trustworthiness: \u001b[95m0.653192\u001b[0m\n","Correlation: \u001b[95m0.996318\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dash/dash.py:587: UserWarning:\n","\n","JupyterDash is deprecated, use Dash instead.\n","See https://dash.plotly.com/dash-in-jupyter for more details.\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","    if (!google.colab.kernel.accessAllowed && !cache) {\n","      return;\n","    }\n","    element.appendChild(document.createTextNode(''));\n","    const url = await google.colab.kernel.proxyPort(port, {cache});\n","    const iframe = document.createElement('iframe');\n","    iframe.src = new URL(path, url).toString();\n","    iframe.height = height;\n","    iframe.width = width;\n","    iframe.style.border = 0;\n","    iframe.allow = [\n","        'accelerometer',\n","        'autoplay',\n","        'camera',\n","        'clipboard-read',\n","        'clipboard-write',\n","        'gyroscope',\n","        'magnetometer',\n","        'microphone',\n","        'serial',\n","        'usb',\n","        'xr-spatial-tracking',\n","    ].join('; ');\n","    element.appendChild(iframe);\n","  })(localhost, \"/\", \"100%\", \"400\", false, window.element)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","    if (!google.colab.kernel.accessAllowed && !cache) {\n","      return;\n","    }\n","    element.appendChild(document.createTextNode(''));\n","    const url = await google.colab.kernel.proxyPort(port, {cache});\n","    const iframe = document.createElement('iframe');\n","    iframe.src = new URL(path, url).toString();\n","    iframe.height = height;\n","    iframe.width = width;\n","    iframe.style.border = 0;\n","    iframe.allow = [\n","        'accelerometer',\n","        'autoplay',\n","        'camera',\n","        'clipboard-read',\n","        'clipboard-write',\n","        'gyroscope',\n","        'magnetometer',\n","        'microphone',\n","        'serial',\n","        'usb',\n","        'xr-spatial-tracking',\n","    ].join('; ');\n","    element.appendChild(iframe);\n","  })(8061, \"/\", \"100%\", 650, false, window.element)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Trustworthiness: \u001b[95m0.597542\u001b[0m\n","Correlation: \u001b[95m0.352667\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dash/dash.py:587: UserWarning:\n","\n","JupyterDash is deprecated, use Dash instead.\n","See https://dash.plotly.com/dash-in-jupyter for more details.\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","    if (!google.colab.kernel.accessAllowed && !cache) {\n","      return;\n","    }\n","    element.appendChild(document.createTextNode(''));\n","    const url = await google.colab.kernel.proxyPort(port, {cache});\n","    const iframe = document.createElement('iframe');\n","    iframe.src = new URL(path, url).toString();\n","    iframe.height = height;\n","    iframe.width = width;\n","    iframe.style.border = 0;\n","    iframe.allow = [\n","        'accelerometer',\n","        'autoplay',\n","        'camera',\n","        'clipboard-read',\n","        'clipboard-write',\n","        'gyroscope',\n","        'magnetometer',\n","        'microphone',\n","        'serial',\n","        'usb',\n","        'xr-spatial-tracking',\n","    ].join('; ');\n","    element.appendChild(iframe);\n","  })(localhost, \"/\", \"100%\", \"400\", false, window.element)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","    if (!google.colab.kernel.accessAllowed && !cache) {\n","      return;\n","    }\n","    element.appendChild(document.createTextNode(''));\n","    const url = await google.colab.kernel.proxyPort(port, {cache});\n","    const iframe = document.createElement('iframe');\n","    iframe.src = new URL(path, url).toString();\n","    iframe.height = height;\n","    iframe.width = width;\n","    iframe.style.border = 0;\n","    iframe.allow = [\n","        'accelerometer',\n","        'autoplay',\n","        'camera',\n","        'clipboard-read',\n","        'clipboard-write',\n","        'gyroscope',\n","        'magnetometer',\n","        'microphone',\n","        'serial',\n","        'usb',\n","        'xr-spatial-tracking',\n","    ].join('; ');\n","    element.appendChild(iframe);\n","  })(8064, \"/\", \"100%\", 650, false, window.element)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 6400x4800 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 6400x4800 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 6400x4800 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 6400x4800 with 0 Axes>"]},"metadata":{}}],"source":["chemical_multiverse(dataset='/content/test.csv', smiles_column_name='Smiles', ID='ID', target_activities=['target_objects'], perplexity=5, n_jobs=-1, evaluation_metric='target_objects', metric_name='Targets', MACCS=False, ECFP=False, signaturizer_code=None)"]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["M2xGGIy-Z0aC"],"authorship_tag":"ABX9TyN1XJGl3GqQqWWiJKDcHX6o"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}